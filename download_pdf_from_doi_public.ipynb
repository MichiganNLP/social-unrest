{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe225c8-3a6b-4ee2-8e49-9f71c0a61946",
   "metadata": {},
   "source": [
    "### This file will download papers to a desired location given its DOI. It should be used right after obtaining a list of DOIs from similar papers to a seed paper (see get_similar_papers.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3561e64a-d6dc-4a8d-a4f8-f847e1f170c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import bibtexparser\n",
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from urllib.parse import quote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36ee4e0-130d-458d-8740-de5da24e998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument(\n",
    "'user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36')\n",
    "\n",
    "options.add_argument(\"enable-automation\");\n",
    "options.add_argument(\"--window-size=1920,1080\");\n",
    "options.add_argument(\"--no-sandbox\");\n",
    "options.add_argument(\"--disable-extensions\");\n",
    "options.add_argument(\"--dns-prefetch-disable\");\n",
    "options.add_argument(\"--disable-gpu\");\n",
    "\n",
    "\n",
    "options.add_experimental_option('prefs', {      \n",
    "\"download.default_directory\": \"/home/bowenyi/side project/get seedpapers/seed paper 3\",  # Papers will be downloaded at this address\n",
    "\"download.prompt_for_download\": False,  \n",
    "\"download.directory_upgrade\": True,\n",
    "\"plugins.always_open_pdf_externally\": True  \n",
    "})\n",
    "\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0a49e60-ab0b-4129-8101-ee27f1ee7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your science_direct api key and insstoken. Insstoken needs to be requested from sciencedirect.com. \n",
    "science_direct_api_key = \"\"  \n",
    "science_direct_insttoken = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f265e26c-b617-4e27-af3c-a62d69e3fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_science_direct(doi, api_key=science_direct_api_key, insttoken=science_direct_insttoken):\n",
    "    url = f\"https://api.elsevier.com/content/article/doi/{doi}?apiKey={api_key}&httpAccept=application%2Fpdf&insttoken={insttoken}\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    pdf_content = response.read()\n",
    "\n",
    "    filename = f\"seed paper 3/{doi.replace('/', '_')}.pdf\"  # Replace with whatever you want to name this pdf\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(pdf_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40296fad-2c84-46ff-941d-5f993285c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_retrieved = []\n",
    "retrieved = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3db17ede-8322-4db3-bf61-1304d90006ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will automatically download a paper to a desired location given its DOI\n",
    "# The download location can be defined in the second cell under options.add_experimental_option -> \"download.default_directory\"   \n",
    "def download_pdf(driver, doi):\n",
    "    url = \"https://doi.org/\" + doi\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    current_url = driver.current_url\n",
    "\n",
    "    if \"sciencedirect\" in current_url:\n",
    "        download_science_direct(doi=doi)\n",
    "        retrieved.append(doi)\n",
    "        return\n",
    "        \n",
    "    url_split = current_url.split(\"/\")\n",
    "    url_find = url_split[-1].split(\"?\")[0]\n",
    "\n",
    "    doi_split = doi.split(\"/\")\n",
    "\n",
    "    # journals.sagepub.com\n",
    "    if \"journals.sagepub.com\" in current_url:\n",
    "        try:\n",
    "            reader_href = f\"https://journals.sagepub.com/doi/reader/{doi}\"\n",
    "            driver.get(reader_href)\n",
    "            time.sleep(1)\n",
    "            download_links = driver.find_elements(By.CSS_SELECTOR, \"a[class*='btn--light btn format-download-btn download']\")\n",
    "            for link in download_links:\n",
    "                href = link.get_attribute('href')\n",
    "                if href:\n",
    "                    driver.get(href)\n",
    "                    time.sleep(1)\n",
    "                    retrieved.append(doi)\n",
    "                    return\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Emerald\n",
    "    if \"www.emerald.com\" in current_url:\n",
    "        try:\n",
    "            href = current_url.replace(\"html\")\n",
    "\n",
    "    # Taylor & Francis\n",
    "    if \"www.tandfonline.com\" in current_url:\n",
    "        try:\n",
    "            doi = current_url.split(\"full/\")[1].split(\"#\")[0]\n",
    "            reader_href = f\"https://www.tandfonline.com/doi/pdf/{doi}/?download=true\"\n",
    "            driver.get(reader_href)\n",
    "            time.sleep(1)\n",
    "            retrieved.append(doi)\n",
    "            return\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # ieee\n",
    "    if \"ieeexplore.ieee.org\" in current_url:\n",
    "        try:\n",
    "            doc_number = current_url.split(\"/\")[-1]\n",
    "            pdf_link = f\"https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber={doc_number}\"\n",
    "            print(pdf_link)\n",
    "            driver.get(pdf_link)\n",
    "            time.sleep(1)\n",
    "            retrieved.append(doi)\n",
    "            return\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # plos:\n",
    "    if \"journals.plos.org\" in current_url:\n",
    "        try:\n",
    "            split = current_url.split(\"?\")\n",
    "            prefix = split[0]\n",
    "            id = split[-1]\n",
    "\n",
    "            url = f\"{prefix}/file?{id}&type=printable\"\n",
    "            driver.get(url)\n",
    "            time.sleep(1)\n",
    "            retrieved.append(doi)\n",
    "            return\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    # # JSTOR: (can't bypass the wall)\n",
    "    if \"www.jstor.org\" in current_url:\n",
    "        not_retrieved.append(doi)\n",
    "        return\n",
    "    \n",
    "\n",
    "    # agupubs.onlinelibrary.wiley.com\n",
    "    if \"agupubs.onlinelibrary.wiley.com\" in current_url:\n",
    "        try:\n",
    "            href = f\"https://agupubs.onlinelibrary.wiley.com/doi/pdfdirect/{doi}?download=true\"\n",
    "            drive.get(href)\n",
    "            time.sleep(1)\n",
    "            retrieved.append(doi)\n",
    "            return\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    # www.mdpi.com\n",
    "    if \"www.mdpi.com\" in current_url:\n",
    "        try:\n",
    "            links = driver.find_element(By.CSS_SELECTOR, 'a=[class*=\"UD_ArticlePDF')\n",
    "            href = link.get_attribute('href')\n",
    "            driver.get(href)\n",
    "            time.sleep(1)\n",
    "            retrieved.append(doi)\n",
    "            return\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "    \n",
    "    # AMS Publications\n",
    "    if \"journals.ametsoc.org\" in current_url:\n",
    "        try:\n",
    "            href = current_url.replace(\"view\", \"downloadpdf/view\").replace(\".xml\", \".pdf\")\n",
    "            driver.get(href)\n",
    "            time.sleep(1)\n",
    "            retrieved.append(doi)\n",
    "            return\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    # Now publisher\n",
    "    if \"nowpublishers\" in current_url:\n",
    "        try:\n",
    "            href = f\"https://www.nowpublishers.com/article/Download/{url_find}\"\n",
    "            driver.get(href)\n",
    "            time.sleep(1)\n",
    "            retrieved.append(doi)\n",
    "            return\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    # a general case for many paper websites\n",
    "    try:\n",
    "        pdf_links = driver.find_elements(By.CSS_SELECTOR, \"a[class*='article-pdfLink']\")\n",
    "        for pdf_link in pdf_links:\n",
    "            href = pdf_link.get_attribute('href')\n",
    "            if href:\n",
    "                driver.get(href)\n",
    "                time.sleep(1)\n",
    "                retrieved.append(doi)\n",
    "                return\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        \n",
    "    # www.degruyter.com\n",
    "    if \"degruyter.com\" in current_url:\n",
    "        try:\n",
    "            pdf_links = driver.find_elements(By.CSS_SELECTOR, \"a[class*='ga_download_button_pdf_article downloadCompletePdfArticle downloadPdf btn btn-primary fw-bold py-2 w-100 vgwort-click']\")\n",
    "            for pdf_link in pdf_links:\n",
    "                href = pdf_link.get_attribute('href')\n",
    "                if href:\n",
    "                    driver.get(href)\n",
    "                    time.sleep(1)\n",
    "                    retrieved.append(doi)\n",
    "                    return\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    # academic.oup.com\n",
    "    if \"academic.oup.com\" in current_url:\n",
    "        try:\n",
    "            pdf_link = driver.find_element(By.CSS_SELECTOR, \"a.al-link.pdf.article-pdfLink\")\n",
    "            href = pdf_link.get_attribute('href')\n",
    "            if href:\n",
    "                driver.get(href)\n",
    "                time.sleep(1)\n",
    "                retrieved.append(doi)\n",
    "                return\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    href_conditions = [\n",
    "        doi_split[-1] + \".pdf\",\n",
    "        doi_split[-1] + \"-pdf\",\n",
    "        doi_split[-1] + \"/pdf\",\n",
    "        \"epdf/\" + doi,\n",
    "        \"reader/\" + doi,\n",
    "        url_find + \"/pdf\",\n",
    "        url_find + \"/pdfft\"\n",
    "    ]   \n",
    "        \n",
    "    # If form is not found, search for href-based downloads\n",
    "    for condition in href_conditions:\n",
    "        try:\n",
    "            # Find an element where the href contains the condition\n",
    "            elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{condition}')]\")\n",
    "            for element in elements:\n",
    "                href = element.get_attribute('href')\n",
    "                driver.get(href)\n",
    "                retrieved.append(doi)\n",
    "                return\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    # Additional check for a condition that occurs in ScienceDirect papers: doi and \"pdf\" present without concatenation\n",
    "    try:\n",
    "        elements = driver.find_elements(By.XPATH, \"//a[contains(@href, 'pdf')]\")\n",
    "        for element in elements:\n",
    "            href = element.get_attribute('href')\n",
    "            if (doi in href and \"pdf\" in href) or (url_find in href and \"pdf\" in href):\n",
    "                driver.get(href)\n",
    "                retrieved.append(doi)\n",
    "                return\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    # Check if there is a form for PDF download\n",
    "    try:\n",
    "        form = driver.find_element(By.XPATH, \"//form[contains(@class, 'ft-download-content__form ft-download-content__form--pdf js-ft-download-form')]\")\n",
    "        if form:                                                       \n",
    "            form.submit()\n",
    "            time.sleep(1)\n",
    "            retrieved.append(doi)\n",
    "            return\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        \n",
    "    not_retrieved.append(doi)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca9b4e-b2a6-411f-b3ac-47e2d52069bc",
   "metadata": {},
   "source": [
    "#### Sample usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb492037-6eb1-4549-ba61-dbf4160ea3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open (\"filtered_papers/filtered_paper_3.json\") as file:\n",
    "    papers = json.load(file)\n",
    "    \n",
    "doi_list = []\n",
    "for paper in papers:\n",
    "    doi = paper[\"doi\"]\n",
    "    doi_list.append(doi.replace(\"DOI \", \"\"))\n",
    "\n",
    "    for ref in paper['references']:\n",
    "        doi_list.append(ref['doi'].replace(\"DOI \", \"\"))\n",
    "\n",
    "for doi in doi_list[7:]:\n",
    "    download_pdf(driver, doi)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3f533a0-bee2-4c6d-8653-641fc08707d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 91 papers. 6 papers unretrieved.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Retrieved {len(retrieved)} papers. {len(not_retrieved)} papers unretrieved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19a442fc-6abe-4942-8d47-f3fee4ef982a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10%2E1016%2Fj%2Eaogh%2E2015%2E08%2E008',\n",
       " '10%2E1016%2Fj%2Eaogh%2E2014%2E09%2E007',\n",
       " '10%2E1108%2FDPM%2D09%2D2013%2D0152',\n",
       " '10%2E12854%2Ferde%2D147%2D7',\n",
       " '10%2E12854%2Ferde%2D147%2D10',\n",
       " '10%2E3167%2Fnc%2E2010%2E050201']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_retrieved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
